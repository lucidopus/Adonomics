# Adonomics: Presentation Script (Samsung/Apple Demo Version)
**Target Duration:** 15-16 Minutes Speaking
**Scenario:** Tech Brand Manager (Samsung/Apple context)

---

## [SLIDE 1: Title Slide - Adonomics]
*(Start with the title slide on screen. Both standing confidently.)*

**(0:00) Krutika:**
Hi everyone, thanks for having us. I’m Krutika, and my background is in Business Analytics.

**(0:10) Harshil:**
And I’m Harshil, I’m an AI Engineer.

**(0:15) Krutika:**
We are here to present **Adonomics**. To put it simply: we are building the "Creative Genome" for modern advertising.

We started this project because we noticed a massive disconnect in the industry. Right now, marketers know exactly *what* happened—they know they got 1,000 clicks or 50 conversions. But they have absolutely no data-backed idea *why* it happened.

**(0:40) Harshil:**
Exactly. Was it the music? Was it the close-up shot of the product? Was it the specific color grading? Right now, figuring that out is just guesswork. We’re here to change that into a science.

---

## [SLIDE 2: The "Black Box" Problem]
*(Slide: Graphic of money going into a machine and a '?' coming out)*

**(1:00) Krutika:**
Let’s look at the current landscape. Brands spend roughly $600 billion a year on digital ads.

The standard process is A/B testing. You throw two videos at a wall, see which one sticks, and throw the other one away. It’s expensive, it’s inefficient, and quite frankly, it’s wasteful.

**(1:30) Krutika:**
As a data person, this drives me crazy. We treat "Creativity" as this magical black box that can’t be measured. We say, "Oh, that ad went viral because it had good vibes."

But in 2025, "vibes" shouldn't be the metric we rely on to spend millions of dollars—especially for high-stakes product launches.

**(1:50) Harshil:**
And that’s where the friction lies. Creative teams speak the language of emotion and story. Performance teams speak the language of ROI. Adonomics is the translator that sits between them.

---

## [SLIDE 3: The Solution - Why? Why Not?]
*(Slide: "Why? Why not?" with the 3 text points)*

**(2:15) Harshil:**
So, we built Adonomics. We use multimodal AI to dissect a video advertisement just like a biologist dissects a cell.

**(2:35) Harshil:**
If you look at the slide, our core technology rests on three pillars:

1.  **Emotional Arc Mapping:** We don't just tag a video as "Happy." We map the journey. Does the excitement rise at the product reveal? Does the tension drop during the tech specs?
2.  **Persuasion Correlation:** This is the "So What?" We take those emotional features and correlate them with actual performance data.
3.  **Creative Recommendations:** Finally, the AI acts as a Creative Assistant, suggesting specific edits to improve performance.

**(3:30) Krutika:**
Think of it as *Moneyball* for video ads. We aren't guessing anymore; we’re looking at the stats behind the art.

---

## [SLIDE 4: The Tech Stack]
*(Slide: Architecture Diagram showing Twelve Labs + Groq)*

**(3:45) Harshil:**
I want to take a moment to look "under the hood," because the tech stack here is something we’re really proud of.

**(4:00) Harshil:**
We aren't just using a generic GPT wrapper.
First, we ingest the video using **Twelve Labs**. This gives us "video understanding"—it identifies objects, actions, and sentiments frame-by-frame.
We combine that with **Groq** for ultra-fast inference.

Basically, our system "watches" the video 1,000 times faster than a human can, tags every element, and stores it.

---

## [LIVE DEMO SECTION]
*(Harshil moves to the laptop/podium to drive. Krutika stands center stage to narrate.)*

**(4:45) Krutika:**
But slides only tell half the story. We want to show you Adonomics in action. Harshil, let’s switch over to the live dashboard.

**[ACTION: Harshil exits slides, opens the Web Browser.]**

**(5:00) Harshil:**
*(Typing/Clicking)*
Okay, so let's roleplay a bit. Imagine I’m a **Brand Manager at Samsung**. We are launching our new flagship phone, and I want to analyze our latest commercial spot before we spend millions on TV placement.

**[ACTION: Harshil clicks "Upload Video" and selects the Phone Ad file.]**

**(5:15) Harshil:**
I’m uploading the 30-second spot. Now, watch the progress bar.
Right now, the video is being sent to the Twelve Labs engine. It’s indexing visual scenes, zooming in on the device features, and analyzing the background music simultaneously.

**(5:30) Krutika:**
*(While loading)*
Normally, an agency team would need hours to watch this, tag every scene, and debate about whether the "camera zoom" shot was effective. The AI is doing this objective analysis in real-time.

**[ACTION: Dashboard loads the analysis results.]**

**(5:45) Harshil:**
And we’re done. Here is the analysis.

**(5:50) Krutika:**
*(Gesturing to screen)*
Okay, look at this. First, you see the **Emotional Arc Graph**.
You can see a massive spike in "Excitement" at the 5-second mark during the high-speed gaming scene. But look at that dip right there around second 12.

**[ACTION: Harshil hovers over the graph at second 12.]**

**(6:10) Harshil:**
The AI actually flagged *why* that dip happened. It identifies the content: *"Scene transitions to heavy text overlay of processor specs. Engagement drops significantly."*

**(6:20) Krutika:**
That is the "Aha!" moment. We assume people want to see the specs, but the data says it’s killing the momentum.
Harshil, what does the **Recommendation Engine** say?

**[ACTION: Harshil scrolls down to "Creative Recommendations"]**

**(6:30) Harshil:**
It’s surprisingly specific. It suggests: *"Replace static text overlay with a visual demonstration of the processor speed—like a fast-loading app—to maintain viewer retention."*

**(6:40) Krutika:**
And that’s the power of Adonomics. We just turned a subjective opinion—"I think the middle part is boring"—into a data-backed fix—"Show, don't tell."

**[ACTION: Harshil switches back to the Presentation Slides.]**

---

## [SLIDE 5: Business Impact]
*(Slide: Table with Roles and Value)*

**(7:00) Krutika:**
So, seeing that demo, you can see how this impacts the bottom line across the ecosystem.

* **For the Brand Manager:** They can justify their media buy with data.
* **For the Creative Director:** It handles the grunt work of analytics so they can focus on the storytelling.
* **For the Agency:** It’s an insurance policy against bad campaigns.

**(7:30) Harshil:**
We’re essentially closing the feedback loop between the person *making* the ad and the person *paying* for the ad.

---

## [SLIDE 6: Try It Out / QR Code]
*(Slide: "Try it out!" with QR Code)*

**(7:45) Harshil:**
Since the backend is live, we’d love for you to try it. You can scan this QR code to see the mobile interface or check out our GitHub repo.

We’re currently inviting beta testers to upload their own video files to help us fine-tune the emotional correlation models.

---

## [SLIDE 7: Thank You / The Vision]
*(Slide: Thank you slide)*

**(8:05) Krutika:**
To wrap up—we think the future of advertising isn't just "Generative AI" where you create fake videos from scratch. We think the immediate, billion-dollar opportunity is in **Analytical AI**—understanding and optimizing the content we already have.

**(8:25) Harshil:**
We’re Adonomics. We’re helping marketers understand *why* things work, so they can make them work again.

**(8:30) Both:**
Thank you. We’d love to answer any questions.